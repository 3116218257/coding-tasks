
## [Aider](https://aider.chat/docs/leaderboards/) Benchmark Task

Aider’s polyglot benchmark evaluates large language models (LLMs) on 225 challenging Exercism coding exercises across multiple languages, including Python.


Your task consists of two parts:

1.  **LLM Serving** 
    - Choose and serve one of the following models using [SgLang](https://github.com/sgl-project/sglang)
        - [Qwen2.5-Coder-0.5B-Instruct](https://huggingface.co/Qwen/Qwen2.5-Coder-0.5B-Instruct)
        - [Qwen2.5-Coder-32B-Instruct](https://huggingface.co/Qwen/Qwen2.5-Coder-32B-Instruct)

2. **Evaluation**:  
   - Evaluate the selected model’s performance on the Python problems from Aider’s polyglot benchmark.
   - Analyze the serving system’s performance, including inference speed.
